[{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/aggregated_counts_1d.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"Aggregated count models in one dimension","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(mgcv) library(ggplot2) library(fmesher) library(patchwork) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/aggregated_counts_1d.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"Aggregated count models in one dimension","text":"Load data rename countdata object cd (just ‘cd’ less type ‘countdata2’.): Take look count data.  Tip: RStudio > Help > Cheatsheets > Data visualisation ggplot2 useful reference ggplot2 syntax.","code":"data(Poisson2_1D) cd <- countdata2 cd #>            x count exposure #> 1   2.319888     9 4.639776 #> 2   6.959664    13 4.639776 #> 3  11.599439    11 4.639776 #> 4  16.239215    22 4.639776 #> 5  20.878991    20 4.639776 #> 6  25.518766    19 4.639776 #> 7  30.158542    16 4.639776 #> 8  34.798318     8 4.639776 #> 9  39.438093     4 4.639776 #> 10 44.077869     4 4.639776 #> 11 48.717645     4 4.639776 ggplot(cd) +   geom_point(aes(x, y = count)) +   ylim(0, max(cd$count))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/aggregated_counts_1d.html","id":"fitting-an-spde-model-with-inlabru","dir":"Articles","previous_headings":"","what":"Fitting an SPDE model with inlabru","title":"Aggregated count models in one dimension","text":"Make mesh. avoid boundary effects region interest, let mesh extend outside data range.","code":"x <- seq(-10, 65, by = 0.5) # this sets mesh points - try others if you like (mesh1D <- fm_mesh_1d(x, degree = 2, boundary = \"free\")) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  151 #>   Interval:  (-10,  65) #>   Boundary:  (free, free) #>   B-spline degree:   2 #>   Basis d.o.f.:  152"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/aggregated_counts_1d.html","id":"using-function-bru-to-fit-to-aggregated-count-data","dir":"Articles","previous_headings":"Fitting an SPDE model with inlabru","what":"Using function bru( ) to fit to aggregated count data","title":"Aggregated count models in one dimension","text":"need specify model components model formula order fit . can done inside call bru( ) bit messy, ’ll store comp first pass bru( ). response variable data frame cd called count model specification needs left ~. add intercept component + Intercept(1) right hand side (models use intercepts), want fit Gaussian random field (GRF), must GRF specification. inlabru GRF specification function, allows GRF calculated point space inlabru calculations. user gets name GRF function. syntax myname(input, model= ...), : ‘myname’ whatever want call GRF (called field ); input specifies coordinates GRF SPDE ‘lives’. working one dimension, called dimension x set data set. model= designates type effect, SPDE model object INLA function inla.spde2.pcmatern( ), requires mesh passed , pass 1D mesh created , mesh1D. models sums model components, don’t need specify full predictor formula. Instead, can provide name output left ~ component specification, “.” right hand side, cause add components (unless subset selected via used argument bru_obs()). Approximate model pretending counts measured individual points: Model takes account expected counts integrals: Predict lambda function (data argument must data frame, see ?predict.bru): Let’s plot compare fitted model true model. true lambda given function lambda2_1D(), expected counts true model stored variable E_nc2 comes dataset Poisson2_1D. ease use plotting ggplot2 (needs data frame), create data frame call true.lambda, containing x- y variables shown . ggplot2 commands generate plot shown . shows true intensities blue line, observed intensities black dots, fitted intensity function red curve, 95% credible intervals shown light bands curves.  can see toy problem, using proper aggregated count observation model doesn’t make noticeable difference fitted model. realistic settings, particular involving high resolution covariates, distinction becomes important, integration scheme resolve small features. computational time available bru_timings():  check iterative method convergence, use bru_convergence_plot():","code":"the_spde <- inla.spde2.pcmatern(mesh1D,   prior.range = c(1, 0.01),   prior.sigma = c(1, 0.01) )  comp <- ~ field(x, model = the_spde) + Intercept(1, prec.linear = 1 / 2^2) fit2.bru <- bru(   comp,   bru_obs(     count ~ .,     data = cd,     family = \"poisson\",     E = exposure   ) )  summary(fit2.bru) #> inlabru version: 2.12.0.9016 #> INLA version: 25.05.18-1 #> Components: #> field: main = spde(x), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Observation models: #>   Family: 'poisson' #>     Tag: '' #>     Data class: 'data.frame' #>     Response class: 'integer' #>     Predictor: count ~ . #>     Additive/Linear: TRUE/TRUE #>     Used components: effects[field, Intercept], latent[] #> Time used: #>     Pre = 0.479, Running = 0.434, Post = 0.0893, Total = 1  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode kld #> Intercept 0.626 0.479     -0.437    0.658       1.52 0.729   0 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                   mean     sd 0.025quant 0.5quant 0.975quant   mode #> Range for field 35.074 19.904     10.922   30.470      86.45 23.073 #> Stdev for field  0.594  0.221      0.275    0.557       1.13  0.488 #>  #> Deviance Information Criterion (DIC) ...............: 59.22 #> Deviance Information Criterion (DIC, saturated) ....: 13.58 #> Effective number of parameters .....................: 5.16 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 57.43 #> Effective number of parameters .................: 2.63 #>  #> Marginal log-Likelihood:  -36.69  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') data_integration <- fm_int(   mesh1D,   samplers = with(cd, cbind(x - exposure/2, x + exposure/2)) ) if (packageVersion(\"inlabru\") >= \"2.12.0.9016\") {   # From 2.12.0.9016:   fit2block.bru <- bru(     comp,     bru_obs(       count ~ .,       data = data_integration,       response_data = cd,       aggregate = \"logsumexp\",       family = \"poisson\"     )   ) } else {   # Before 2.12.0.9016:   fit2block.bru <- bru(     comp,     bru_obs(       count ~ fm_block_logsumexp_eval(         block = .block,         weights = weight,         n_block = NROW(cd),         values = Intercept + field       ),       allow_combine = TRUE,       data = data_integration,       response_data = cd,       family = \"poisson\"     )   ) }  summary(fit2block.bru) #> inlabru version: 2.12.0.9016 #> INLA version: 25.05.18-1 #> Components: #> field: main = spde(x), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Observation models: #>   Family: 'poisson' #>     Tag: '' #>     Data class: 'tbl_df', 'tbl', 'data.frame' #>     Response class: 'integer' #>     Predictor: count ~ . #>     Additive/Linear: FALSE/FALSE #>     Used components: effects[field, Intercept], latent[] #> Time used: #>     Pre = 0.344, Running = 0.455, Post = 0.0817, Total = 0.88  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode kld #> Intercept 0.627 0.472     -0.419    0.659      1.508 0.729   0 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                   mean     sd 0.025quant 0.5quant 0.975quant   mode #> Range for field 33.590 19.718      9.978   28.954      84.61 21.549 #> Stdev for field  0.595  0.218      0.279    0.559       1.12  0.492 #>  #> Deviance Information Criterion (DIC) ...............: 59.02 #> Deviance Information Criterion (DIC, saturated) ....: 13.38 #> Effective number of parameters .....................: 5.01 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 57.29 #> Effective number of parameters .................: 2.57 #>  #> Marginal log-Likelihood:  -36.58  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') x4pred <- data.frame(x = seq(0, 55, by = 0.1)) pred2.bru <- predict(fit2.bru,   x4pred,   x ~ exp(field + Intercept),   n.samples = 1000 ) pred2block.bru <- predict(fit2.bru,   x4pred,   x ~ exp(field + Intercept),   n.samples = 1000 ) true.lambda <- data.frame(x = x4pred$x, lambda = lambda2_1D(x4pred$x)) ggplot() +   gg(pred2.bru) +   gg(pred2block.bru,mapping = aes(fill=\"red\"), alpha=0.2, color = \"red\") +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_line(data = true.lambda, aes(x, lambda), col = \"blue\") +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\") #> Warning in ggplot2::geom_line(data = data, line.map, ...): Ignoring #> unknown aesthetics: fill bru_timings(fit2.bru) #>         Task Iteration       Time     System    Elapsed #> 1 Preprocess         0 0.360 secs 0.029 secs 0.374 secs #> 2 Preprocess         1 0.103 secs 0.012 secs 0.110 secs #> 3 Run inla()         1 0.974 secs 0.132 secs 1.032 secs bru_timings(fit2block.bru) #>          Task Iteration       Time     System    Elapsed #> 1  Preprocess         0 0.099 secs 0.023 secs 0.110 secs #> 2  Preprocess         1 0.202 secs 0.000 secs 0.202 secs #> 3  Run inla()         1 0.662 secs 0.072 secs 0.750 secs #> 4 Line search         1 0.014 secs 0.000 secs 0.014 secs #> 5  Preprocess         2 0.206 secs 0.000 secs 0.206 secs #> 6  Run inla()         2 0.671 secs 0.052 secs 0.750 secs #> 7 Line search         2 0.224 secs 0.000 secs 0.224 secs #> 8  Preprocess         3 0.167 secs 0.000 secs 0.168 secs #> 9  Run inla()         3 0.900 secs 0.060 secs 0.904 secs bru_timings_plot(fit2block.bru) bru_convergence_plot(fit2block.bru)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/install.html","id":"installing-inla-and-inlabru","dir":"Articles","previous_headings":"","what":"Installing INLA and inlabru","title":"Software installation","text":"Due work involved building binaries INLA package C software different architectures, INLA package CRAN, can installed distribution repository. easiest approach add repository local R options, e.g. ~/.Rprofile, install.packages(\"INLA\") can work usual. Alternatively, repository information can supplied via install.packages(\"INLA\", repos = ...). ~/.Rprofile, add following lines, run code R session: Note: installed INLA \"stable\" repository instead \"testing\", may need upgrade \"testing\" version, typically contains bug fixes improvements, version inlabru tested . third repository optional, gives easy access development versions inlabru (2.12.0.9016 later) fmesher (0.3.0.9008 later, package dependency INLA inlabru). tutorials course work CRAN versions inlabru fmesher, 2.12.0, installing development version r-universe.dev recommended, required new features contains bug fixes, see inlabru changelog. install packages, including optional dependencies many required data analysis, run following code R session: warning unavailable HKprocess package can safely ignored. INLA also suggests two Bioconductor packages, graph Rgraphviz, essential course, can installed ","code":"local({   r <- c(INLA = \"https://inla.r-inla-download.org/R/testing\",          CRAN = \"https://cloud.r-project.org/\",          inlabru_universe = \"https://inlabru-org.r-universe.dev\")   options(repos = r) }) install.packages(c(\"INLA\", \"inlabru\"), dependencies = TRUE) if (!requireNamespace(\"BiocManager\", quietly = TRUE)) {   install.packages(\"BiocManager\") } BiocManager::install(c(\"graph\", \"Rgraphviz\"), dep = TRUE)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/install.html","id":"installation-check","dir":"Articles","previous_headings":"","what":"Installation check","title":"Software installation","text":"Please check installation using basic model runs . run issues, can post question information tried didn’t work, course github discussion page Finn reply ’s able. Since 29 April 2025, latest INLA package built R 4.5, ’re able upgrade R installation, please avoid unnecessary issues. package many cases also work older R versions, compatibility sometimes difficult. can check INLA correctly installed running simple inla() call fails crash, may need install different inla binaries hardware/software combination, INLA::inla.binary.install(). inla() works, can check inlabru installed correctly running model inlabru:","code":"df <- data.frame(y = rnorm(100) + 10) fit <- INLA::inla(   y ~ 1,   data = df ) summary(fit) #> Time used: #>     Pre = 0.374, Running = 0.245, Post = 0.0139, Total = 0.633  #> Fixed effects: #>               mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> (Intercept) 10.071 0.105      9.865   10.071     10.277 10.071   0 #>  #> Model hyperparameters: #>                                          mean   sd 0.025quant 0.5quant #> Precision for the Gaussian observations 0.924 0.13      0.687    0.918 #>                                         0.975quant  mode #> Precision for the Gaussian observations       1.20 0.905 #>  #> Marginal log-Likelihood:  -158.73  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') fit <- inlabru::bru(   y ~ Intercept(1, prec.linear = exp(-7)),   data = df ) summary(fit) #> inlabru version: 2.12.0.9016 #> INLA version: 25.05.18-1 #> Components: #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Observation models: #>   Family: 'gaussian' #>     Tag: '' #>     Data class: 'data.frame' #>     Response class: 'numeric' #>     Predictor: y ~ . #>     Additive/Linear: TRUE/TRUE #>     Used components: effects[Intercept], latent[] #> Time used: #>     Pre = 0.226, Running = 0.253, Post = 0.0359, Total = 0.515  #> Fixed effects: #>             mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> Intercept 10.071 0.105      9.865   10.071     10.277 10.071   0 #>  #> Model hyperparameters: #>                                          mean   sd 0.025quant 0.5quant #> Precision for the Gaussian observations 0.924 0.13      0.687    0.918 #>                                         0.975quant  mode #> Precision for the Gaussian observations       1.20 0.905 #>  #> Deviance Information Criterion (DIC) ...............: 296.69 #> Deviance Information Criterion (DIC, saturated) ....: 104.35 #> Effective number of parameters .....................: 1.99 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 296.96 #> Effective number of parameters .................: 2.19 #>  #> Marginal log-Likelihood:  -163.19  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"continuous-variables-gaussian-mrfs","dir":"Articles","previous_headings":"Spatial dependence structures > Graph dependent structures; Markov random fields","what":"Continuous variables; Gaussian MRFs","title":"Random field and latent models","text":"Covariance Precision matrices Multivariate vectors covariance precision representation dependence: \\[ \\begin{aligned} u &\\sim N(\\mu_u,\\Sigma_u) \\\\ u &\\sim N(\\mu_u,Q_u^{-1}) \\end{aligned} \\] Observations additive noise: \\[ y|u \\sim N(\\eta = b + u, Q_\\epsilon^{-1}) \\] Joint covariance: \\[ \\Sigma_{(u,y)} = \\begin{bmatrix} \\Sigma_u & \\Sigma_u ^\\top \\\\ ^\\top \\Sigma_u & \\Sigma_u ^\\top + Q_\\epsilon^{-1} \\end{bmatrix} \\] Joint precision: \\[ Q_{(u,y)} = \\begin{bmatrix} Q_u + ^\\top Q_\\epsilon & -^\\top Q_\\epsilon \\\\ -Q_\\epsilon & Q_\\epsilon \\end{bmatrix} \\] Conditional distributions: \\[ \\begin{aligned} u|y &\\sim N(\\mu_{u|y},\\Sigma_{u|y}) \\\\ \\Sigma_y &= \\Sigma_u ^\\top + Q_\\epsilon^{-1} \\\\ \\Sigma_{u|y} &= \\Sigma_u - \\Sigma_u ^\\top \\Sigma_y^{-1} \\Sigma_u \\\\ \\mu_{u|y} &= \\mu_u + \\Sigma_u ^\\top \\Sigma_y^{-1} (y - b - \\mu_u) \\\\ \\end{aligned} \\] \\[ \\begin{aligned} u|y &\\sim N(\\mu_{u|y},Q_{u|y}^{-1}) \\\\ Q_{u|y} &= Q_u + ^\\top Q_\\epsilon \\\\ \\mu_{u|y} &= \\mu_u + Q_{u|y}^{-1} ^\\top Q_\\epsilon (y - b - \\mu_u) \\end{aligned} \\]","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"basis-function-representations","dir":"Articles","previous_headings":"Spatial dependence structures > Gaussian processes/random fields","what":"Basis function representations","title":"Random field and latent models","text":"Changing knot sequence keeping weights independent drastically changes model.  SPDE approach provides method constructing basis weight dependence structures consistent changing knot sequence /basis functions, projecting continuously defined process model onto function space defined given set basis functions. main requirement basis functions need able resolve features certain scale, determined correlation length process model.","code":"(m <- fm_mesh_1d(   loc = seq(0, 1, length.out = 10),   degree = 2 )) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  10 #>   Interval:  (0, 1) #>   Boundary:  (neumann, neumann) #>   B-spline degree:   2 #>   Basis d.o.f.:  9 ggplot() +   geom_fm(data = m) (m1 <- fm_mesh_1d(m$mid, degree = 1)) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  9 #>   Interval:  (0.05555556, 0.94444444) #>   Boundary:  (neumann, neumann) #>   B-spline degree:   1 #>   Basis d.o.f.:  9 ggplot() +   geom_fm(data = m) +   geom_fm(data = m1, xlim = m$interval) ggplot() +   geom_fm(data = m, weights = rnorm(fm_dof(m), sd = 0.5), knots = FALSE) (m_dense <- fm_mesh_1d(   loc = seq(0, 1, length.out = 100)^0.5,   degree = 2 )) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  100 #>   Interval:  (0, 1) #>   Boundary:  (neumann, neumann) #>   B-spline degree:   2 #>   Basis d.o.f.:  99 ggplot() +   geom_fm(     data = m_dense,     weights = rnorm(fm_dof(m_dense), sd = 0.5),     knots = FALSE,     basis = FALSE   ) (m_dense2 <- fm_mesh_1d(   loc = seq(0, 1, length.out = 1000),   degree = 2 )) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  1000 #>   Interval:  (0, 1) #>   Boundary:  (neumann, neumann) #>   B-spline degree:   2 #>   Basis d.o.f.:  999 Q_m <- fm_matern_precision(m, alpha = 2, rho = 0.3, sigma = 0.5) Q_m_dense <- fm_matern_precision(m_dense, alpha = 2, rho = 0.3, sigma = 0.5) Q_m_dense2 <- fm_matern_precision(m_dense2, alpha = 2, rho = 0.3, sigma = 0.5) ggplot() +   geom_fm(     data = m,     mappings = list(fun = aes(col = \"m\")),     weights = fm_sample(1, Q_m),     knots = FALSE,     basis = FALSE   ) +   geom_fm(     data = m_dense,     mappings = list(fun = aes(col = \"m_dense\")),     weights = fm_sample(1, Q_m_dense),     knots = FALSE,     basis = FALSE   ) +   geom_fm(     data = m_dense2,     mappings = list(fun = aes(col = \"m_dense2\")),     weights = fm_sample(1, Q_m_dense2),     knots = FALSE,     basis = FALSE   ) (m_dense2 <- fm_mesh_1d(   loc = seq(0, 1, length.out = 1000),   degree = 2 )) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  1000 #>   Interval:  (0, 1) #>   Boundary:  (neumann, neumann) #>   B-spline degree:   2 #>   Basis d.o.f.:  999 Q_m <- fm_matern_precision(m, alpha = 1, rho = 0.3, sigma = 0.5) Q_m_dense <- fm_matern_precision(m_dense, alpha = 1, rho = 0.3, sigma = 0.5) Q_m_dense2 <- fm_matern_precision(m_dense2, alpha = 1, rho = 0.3, sigma = 0.5) ggplot() +   geom_fm(     data = m,     mappings = list(fun = aes(col = \"m\")),     weights = fm_sample(1, Q_m),     knots = FALSE,     basis = FALSE   ) +   geom_fm(     data = m_dense,     mappings = list(fun = aes(col = \"m_dense\")),     weights = fm_sample(1, Q_m_dense),     knots = FALSE,     basis = FALSE   ) +   geom_fm(     data = m_dense2,     mappings = list(fun = aes(col = \"m_dense2\")),     weights = fm_sample(1, Q_m_dense2),     knots = FALSE,     basis = FALSE   )"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"d","dir":"Articles","previous_headings":"Spatial dependence structures","what":"2D","title":"Random field and latent models","text":"","code":"(m <- fm_mesh_2d(   boundary = list(fm_nonconvex_hull_inla(cbind(0, 0), convex = 5)),   max.edge = 1 )) #> fm_mesh_2d object: #>   Manifold:  R2 #>   V / E / T: 233 / 642 / 410 #>   Euler char.:   1 #>   Constraints:   Boundary: 54 boundary edges (1 group: 1), Interior: 0 edges #>   Bounding box: (-4.996242, 4.996242) x (-4.996242, 4.996242) #>   Basis d.o.f.:  233 ggplot() +   geom_fm(data = m) (m2 <- fm_mesh_2d(   boundary = fm_extensions(cbind(0, 0), convex = c(5, 10)),   max.edge = c(0.5, 2) )) #> fm_mesh_2d object: #>   Manifold:  R2 #>   V / E / T: 1002 / 2961 / 1960 #>   Euler char.:   1 #>   Constraints:   Boundary: 42 boundary edges (1 group: 1), Interior: 88 interior edges (1 group: 1) #>   Bounding box: (-9.999247, 9.999247) x (-9.999247, 9.999247) #>   Basis d.o.f.:  1002 ggplot() +   geom_fm(data = m2) bnd <- fm_extensions(cbind(0, 0), convex = c(5, 10)) (m3 <- fm_mesh_2d(   loc = fm_hexagon_lattice(bnd[[1]], edge_len = 0.5),   boundary = bnd,   max.edge = c(0.6, 2) )) #> fm_mesh_2d object: #>   Manifold:  R2 #>   V / E / T: 602 / 1764 / 1163 #>   Euler char.:   1 #>   Constraints:   Boundary: 39 boundary edges (1 group: 1), Interior: 74 interior edges (1 group: 1) #>   Bounding box: (-9.999247, 9.999247) x (-9.999247, 9.999247) #>   Basis d.o.f.:  602 ggplot() +   geom_fm(data = m3)"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"coupling-latent-variables-to-observations","dir":"Articles","previous_headings":"Observations","what":"Coupling latent variables to observations","title":"Random field and latent models","text":"observations almost always finite-dimensional, latent variables random effects often infinite-dimensional, least conceptually. means need careful link observations latent variables. benefit way thinking allows us link misaligned observation structures latent models, can jointly model different types observations without necessarily adapt latent structures.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"pointgeoreferenced-data","dir":"Articles","previous_headings":"Observations","what":"Point/Georeferenced data","title":"Random field and latent models","text":"Classical geostatistical models additive Gaussian noise: \\[ y_i = \\eta(s_i) + \\epsilon_i \\] Poisson counts given locations: \\[ y_i \\sim \\text{Po}(e^{\\eta(s_i)} ds) \\]","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"arealaggregated-data","dir":"Articles","previous_headings":"Observations","what":"Areal/aggregated data","title":"Random field and latent models","text":"observations constructed aggregation region \\(B_i\\), need determine aggregated values link continuous domain predictor. averaged predictor additive Gaussian noise: \\[ y_i = \\frac{1}{|B_i|}\\int_{B_i} \\eta(s) ds + \\epsilon_i \\] data consists sums Poisson counts different locations, get \\[ y_{B_j} = \\#\\{; s_i\\B_j\\} \\sim \\text{Po}\\left(\\sum_{s_i\\B_j} e^{\\eta(s_i)}\\right) \\] Note aggregating linear predictor , due nonlinear transformation. Also note situation much complicated non-Poisson count models, since example sum two independent Binomial variables, \\(\\text{Bin}(n_1, p_1)+\\text{Bin}(n_2, p_2)\\) Binomial unless \\(p_1=p_2\\). data consists counts Poisson process point pattern data \\(\\{s_i;=1\\dots,N(\\Omega)\\}\\), aggregated regions \\(B_j\\), can use following model, directly based properties Posson point process. \\[ y_{B_j} = \\#\\{; s_i\\B_j\\} \\sim \\text{Po}\\left(\\int_{B_j} e^{\\eta(s)} \\,ds\\right) \\]","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"point-pattern-data","dir":"Articles","previous_headings":"Observations","what":"Point pattern data","title":"Random field and latent models","text":"Poisson point process random process generates points space count points given set \\(B\\) Poisson distributed expectation \\(\\Lambda(B)=\\int_B \\lambda(s)\\,ds\\), \\(\\lambda(s)\\) intensity function. Log-Gaussian Cox processes obtained \\(\\lambda(s)=e^{\\eta(s)}\\) \\(\\eta(s)\\) Gaussian random field. Poisson process point pattern sampling region \\(\\Omega\\) set conditional distribution \\[ \\{s_i;s_i\\\\Omega\\} \\sim \\text{PoPr}\\left(e^{\\eta(\\cdot)}\\right) \\] means every set \\(B\\subseteq\\Omega\\), \\[ \\#\\{s_i;s_i\\B\\} \\sim \\text{Po}\\left(\\int_B e^{\\eta(s)}\\,ds\\right) . \\]","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"latent-gaussian-models-for-geostatistics","dir":"Articles","previous_headings":"","what":"Latent Gaussian models for geostatistics","title":"Random field and latent models","text":"INLA implements models observation \\(y_i\\) linked element linear predictor vector, \\(\\eta_i\\), typically controls location parameter observation model, link function \\(g(\\cdot)\\), conditional independence, given \\(\\eta\\). linear predictor","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"classic-inla","dir":"Articles","previous_headings":"inlabru model structure","what":"Classic INLA","title":"Random field and latent models","text":"Classic INLA model formulas designed closely follow basic additive model formula syntax, defines model linear predictor form \\[ \\eta_i = \\beta_0 + \\beta_1 x_{,1} + \\beta_2 x_{,2} + u_i \\] \\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\) independent Gaussian scalars, \\(u_i\\) unstructured structured latent Gaussian random effect. INLA::f() components, name input variable also becomes name effect. spatial models, field variable need defined index mesh nodes, usually constructed inla.spde.make.index(), inla.spde.make.() inla.stack() used construct mapping information required inform INLA nodes linked observations. One aims inlabru provide compact flexible syntax defining models, automatically handling mapping structured latent variables observations. ’ve used “raw” INLA approach, please consult Converting inla.spde.make.calls bru_mapper system.","code":"response ~ 1 + covariate1 + covariate2 + f(field, model = model_name)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"inlabru","dir":"Articles","previous_headings":"inlabru model structure","what":"inlabru","title":"Random field and latent models","text":"inlabru uses conceptual information flow model definition: latent model components component effects predictor expressions observation models","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"model-components-and-effects","dir":"Articles","previous_headings":"inlabru model structure > inlabru","what":"Model components and effects","title":"Random field and latent models","text":"Model components defined way decouples input data names effect model component. allows variable involved several components, without need creating dummies copies. component takes general R expression input, evaluated context observation model data. bru_mapper() system used construct per-component model matrices, combined joint model matrix based predictor expressions. basic syntax effect_name(input_variable, model = ...), defines effect input variable, using specified model. model can INLA model, \"iid\", \"ar1\", \"rw2\", \"bym2\", inla.spde2.pcmatern() model object, user-defined model (rgeneric/cgeneric). standard INLA models default mappers associated , user-defined model can associated mapper using bru_get_mapper() method, explicitly provided user. default input expression name components, classical effects can written + covar, shorthand + covar(covar, model = \"linear\"). , component effect called field, input geometry variable sf data, mapper automatically constructed bru_mapper_fmesher() mapper mesh used model definition. two kinds mappers; Non-indexed mappers provide raw covariate values input INLA::f(), used fixed effects rw1/rw2 models. Indexed mappers used build models integers categories. details component definitions, see Defining model components -depth discussion mapper system, including define complex fixed effects components (model=\"fixed\" together bru_mapper_matrix() )custom mappers, Customised model components bru_mapper system.","code":"response ~ Intercept(1) +   covariate1 +   covariate2 +   field(geometry, model = inla.spde2.pcmatern(...))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"predictor-expressions","dir":"Articles","previous_headings":"inlabru model structure > inlabru","what":"Predictor expressions","title":"Random field and latent models","text":"compatibility basic glm formulas, inlabru default constructs predictor expression adds component effects, response variable named left ~ operator. following code, equivalent ~ . shorthand complete additive model. limit variables added, one can use used argument bru_obs() specify particular component subset. version 2.12.0, specifying explicit expression instead ~ . shorthand cause predictor interpreted non-linear expression, activate iterative linearisation method. 2.12.0.9014, purely additive expressions, response ~ Intercept + field, detected automatically.","code":"bru(   response ~ Intercept(1) +     covariate1 +     covariate2 +     field(geometry, model = inla.spde2.pcmatern(...)),   ... ) bru(   ~ Intercept(1) +     covariate1 +     covariate2 +     field(geometry, model = inla.spde2.pcmatern(...)),   bru_obs(     response ~ .,     ...   ) )"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"non-linear-predictors-and-mappers","dir":"Articles","previous_headings":"","what":"Non-linear predictors and mappers","title":"Random field and latent models","text":"inlabru provides flexible framework defining non-linear predictors arbitrary R expressions, well applying nonlinear transformations model component effects directly. non-linear predictor models, inlabru uses iterative linearisation method. non-linear predictor \\(\\widetilde{\\eta}(u)\\) replaced linear approximation \\(\\overline{\\eta}^*(u) = b + u\\), constructed current best conditional posterior mode, \\(u^*\\). INLA run yields new candidate point \\(\\widehat{u}\\). next linearisation point chosen line-search, \\[ \\gamma = \\arg\\min_\\gamma \\left\\| \\widetilde{\\eta}^*\\left((1-\\gamma) u^* + \\gamma \\widehat{u}\\right) - \\overline{\\eta}^*(\\widehat{u})\\right\\|_\\text{(weighted posterior variances)} \\] defining new linearisation point \\(u^*_\\text{new}=(1-\\gamma) u^* + \\gamma \\widehat{u}\\). linearisation repeated convergence, .e. changes \\(u^*\\) small relation posterior standard deviations. Use bru_convergence_plot(fit) see post-run convergence diagnostics, can reveal potential problems aid debugging.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"non-linear-expressions","dir":"Articles","previous_headings":"Non-linear predictors and mappers","what":"Non-linear expressions","title":"Random field and latent models","text":"simple example use exp() function model positive additive effect: can particularly useful multi-observation models common effects: type scaling parameter, one normally use specific prior distribution beta_field_B, can done using component marginal transformation mapper, see .","code":"comp <- ~ 0 + beta0(1) + field(geometry, model = matern) form <- y ~ beta0 + exp(field) comp <- ~ 0 +   beta0_A(1) +   beta0_B(1) +   beta_field_B(1) +   field(geometry, model = matern) form_A <- y_A ~ beta0_A + field form_B <- y_B ~ beta0_B + exp(beta_field_B) * field"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"aggregation","dir":"Articles","previous_headings":"Non-linear predictors and mappers > Non-linear mappers","what":"Aggregation","title":"Random field and latent models","text":"bru_mapper_aggregate() bru_mapper_logsumexp() aggregation mappers linear nonlinear aggregation functions, respectively, averaging total sum/integral aggregation. inlabru version 2.12.0.9013, first method can used construct four aggregation types, via bru_mapper_aggregate(type = ...) transforming interactively expressions, may preferable call core fmesher functions fm_block_eval() fm_block_logsumexp_eval() directly instead create explicit mapper object calling ibm_eval(mapper, ...).","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"marginal-transformations","dir":"Articles","previous_headings":"Non-linear predictors and mappers > Non-linear mappers","what":"Marginal transformations","title":"Random field and latent models","text":"transform \\(N(0,1)\\) variables marginally distributions, can use bru_mapper_marginal() mapper. applies careful numerical transformations computes Jacobian transformation, predictor linearisation can compute overall linearised mapping latent variables observations using chain rule. following defines beta_field_B component effect distributed \\(\\text{Exp}(1)\\):","code":"comp <- ~ 0 +   beta0_A(1) +   beta0_B(1) +   beta_field_B(1,     prec.linear = 1,     marginal = bru_mapper_marginal(qexp, rate = 1)   ) +   field(geometry, model = matern) form_A <- y_A ~ beta0_A + field form_B <- y_B ~ beta0_B + beta_field_B * field"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"posterior-predictive-checks","dir":"Articles","previous_headings":"Model assessment","what":"Posterior predictive checks","title":"Random field and latent models","text":"global model diagnostic scores DIC WAIC can useful basic model comparison, often informative way one model might better worse another, lack interpretability, particular spatial behavior model. informative approach use posterior predictive checks, can compute overall scores spatially resolved scores. general introduction compute posterior observation level prediction scores, see inlabru package vignette Prediction scores","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"proper-scoring-rules","dir":"Articles","previous_headings":"Model assessment > Posterior predictive checks","what":"Proper scoring rules","title":"Random field and latent models","text":"Posterior samples can used compute proper scoring rules. (new) observation \\(y_i\\) posterior predictive model \\(F_i\\), proper score \\(S(F,y)\\) function posterior predictive distribution \\(F\\) observation \\(y\\) \\(G\\) true predictive distribution, expectation \\(S(F,G)=E_{y\\sim G}[S(F,y)]\\) fulfils \\(S(F,G)\\geq S(G,G)\\), .e. average, score minimized predictive distribution equal true distribution. score strictly proper equality obtained \\(F=G\\). Generally easy compute/estimate: Squared Error: \\(S_\\text{SE}(F,y)=[y - E_F(y)]^2\\) Dawid-Sebastiani: \\(S_\\text{DS}(F,y)=\\frac{[y - E_F(y)]^2}{V_F(y)}+\\log[V_F(y)]\\) Log-score: \\(S_\\text{LS}(F,y)=-\\log p_F(y)\\) difficult compute/estimate: Absolute Error: \\(S_\\text{AE}(F,y)=\\left|y - \\text{median}_F(y)\\right|\\) CRPS: \\(S_\\text{CRPS}(F,y)=\\int_\\mathbb{R} \\left[F(x) - \\mathbb{}(y\\leq x)\\right]^2 \\,dx\\) average prediction scores defined \\[ \\overline{S}(\\{F_i\\},\\{y_i\\}) = \\frac{1}{N}\\sum_{=1}^N S(F_i,y_i) \\] \\(N\\) number prediction observations. comparing models B, one work collection individual score differences, since scores \\(S(F_i^,y_i)\\) \\(S(F_i^B,y_i)\\) dependent, need treat paired samples. define \\[ S_\\Delta(F_i^,F_i^B,y_i) = S(F_i^B,y_i) - S(F_i^,y_i) \\] get \\[ V\\left[\\overline{S}(\\{F_i^B\\},\\{y_i\\}) - \\overline{S}(\\{F_i^B\\},\\{y_i\\})\\right] \\approx \\frac{1}{N} V\\left[S(F_i^B,y_i) - S(F_i^,y_i)\\right] \\]","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lecture_notes.html","id":"point-process-residuals","dir":"Articles","previous_headings":"Model assessment","what":"Point process residuals","title":"Random field and latent models","text":"See inlabru package vignette Residual Analysis spatial point process models using Bayesian methods","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - Spatial covariates","text":"going fit spatial models gorilla data, using factor continuous explanatory variables practical. fit one using factor variable vegetation, using continuous covariate elevation (Jump bottom practical want start gently 1D example!)","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - Spatial covariates","text":"dataset list (see help(gorillas_sf) details. Extract objects need list, convenience:","code":"data(gorillas_sf, package = \"inlabru\") nests <- gorillas_sf$nests mesh <- gorillas_sf$mesh boundary <- gorillas_sf$boundary gcov <- gorillas_sf_gcov() #> Loading required namespace: terra"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"factor-covariates","dir":"Articles","previous_headings":"","what":"Factor covariates","title":"LGCPs - Spatial covariates","text":"Look vegetation type, nests boundary:  , mesh:","code":"ggplot() +   gg(gcov$vegetation) +   gg(boundary, alpha = 0.2) +   gg(nests, color = \"white\", cex = 0.5) ggplot() +   gg(gcov$vegetation) +   gg(mesh) +   gg(boundary, alpha = 0.2) +   gg(nests, color = \"white\", cex = 0.5)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"a-model-with-vegetation-type-only","dir":"Articles","previous_headings":"Factor covariates","what":"A model with vegetation type only","title":"LGCPs - Spatial covariates","text":"seems vegetation type might good predictor nearly nests fall vegetation type Primary. construct model vegetation type fixed effect. , need tell ‘lgcp’ find vegetation type point space, creating model components fixed effect call vegetation (call anything), follows: Notes: * need tell ‘lgcp’ factor fixed effect, model=\"factor_full\", giving one coefficient factor level. * need careful overparameterisation using factors. Unlike regression models like ‘lm()’, ‘glm()’ ‘gam()’, ‘lgcp()’, inlabru automatically remove first level absorb intercept. Instead, can either use model=\"factor_full\" without intercept, model=\"factor_contrast\", remove first level. Fit model usual: Predict intensity, plot median intensity surface. (older versions, predicting takes time vegetation values outside mesh ‘inlabru’ needed predict first. Since v2.0.0, vegetation pre-extended.) predict function inlabru takes data argument sf object object supported predictor evaluation code (non-geographical data, typically data.frame). can use inlabru function pixels generate sf object points within boundary, using mask argument, shown .  surprisingly, given nests Primary vegetation, high density vegetation. substantial patches predicted high density nests, areas predicted low density nests. estimated abundance (really 647 nests ):","code":"comp1 <- geometry ~ vegetation(gcov$vegetation, model = \"factor_full\") - 1 comp1alt <- geometry ~ vegetation(gcov$vegetation, model = \"factor_contrast\") +   Intercept(1) fit1 <- lgcp(comp1, nests, samplers = boundary, domain = list(geometry = mesh)) pred.df <- fm_pixels(mesh, mask = boundary) int1 <- predict(fit1, pred.df, ~ exp(vegetation))  # gg() with sf points and geom = \"tile\" plots a raster ggplot() +   gg(int1, geom = \"tile\") +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests, color = \"DarkGreen\") ips <- fm_int(mesh, boundary) Lambda1 <- predict(fit1, ips, ~ sum(weight * exp(vegetation))) Lambda1 #>       mean       sd   q0.025     q0.5  q0.975   median sd.mc_std_err #> 1 647.7046 22.50478 609.6449 645.6795 701.032 645.6795      1.811113 #>   mean.mc_std_err #> 1          2.6127"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"a-model-with-vegetation-type-and-a-spde-type-smoother","dir":"Articles","previous_headings":"Factor covariates","what":"A model with vegetation type and a SPDE type smoother","title":"LGCPs - Spatial covariates","text":"Lets try explain pattern nest distribution captured vegetation covariate, using SPDE: plot posterior median intensity surface  … expected integrated intensity (mean abundance) Look contributions linear predictor SPDE vegetation: function scale_fill_gradientn sets scale plot legend. set span range three linear predictor components plotted (medians plotted default).","code":"pcmatern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.1, 0.01) )  comp2 <- geometry ~   -1 +   vegetation(gcov$vegetation, model = \"factor_full\") +   mySmooth(geometry, model = pcmatern) fit2 <- lgcp(comp2, nests, samplers = boundary, domain = list(geometry = mesh)) int2 <- predict(fit2, pred.df, ~ exp(mySmooth + vegetation), n.samples = 1000)  ggplot() +   gg(int2, aes(fill = q0.5), geom = \"tile\") +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests) Lambda2 <- predict(   fit2,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + vegetation)) ) Lambda2 #>       mean       sd  q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 675.7068 25.20024 630.697 678.4432 723.4977 678.4432      1.726406 #>   mean.mc_std_err #> 1        2.865305 lp2 <- predict(fit2, pred.df, ~ list(   smooth_veg = mySmooth + vegetation,   smooth = mySmooth,   veg = vegetation )) lprange <- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.lp2 <- ggplot() +   gg(lp2$smooth_veg, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth + vegetation\")  plot.lp2.spde <- ggplot() +   gg(lp2$smooth, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth\")  plot.lp2.veg <- ggplot() +   gg(lp2$veg, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"vegetation\")  multiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, cols = 3)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"a-model-with-spde-only","dir":"Articles","previous_headings":"Factor covariates","what":"A model with SPDE only","title":"LGCPs - Spatial covariates","text":"need vegetation ? Fit model SPDE + Intercept, choose models basis DIC, using deltaIC().  NOTE: behaviour DIC currently bit unclear, investigated. WAIC related leave-one-cross-validation, appropriate use current current LGCP likelihood implementation. Classic mode: Experimental mode:","code":"comp3 <- geometry ~ mySmooth(geometry, model = pcmatern) + Intercept(1) fit3 <- lgcp(comp3,   data = nests,   samplers = boundary,   domain = list(geometry = mesh) ) int3 <- predict(fit3, pred.df, ~ exp(mySmooth + Intercept))  ggplot() +   gg(int3, geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests) Lambda3 <- predict(   fit3,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda3 #>       mean       sd   q0.025     q0.5  q0.975   median sd.mc_std_err #> 1 674.2319 25.84747 615.8135 674.2253 717.566 674.2253      1.691668 #>   mean.mc_std_err #> 1        2.923081 knitr::kable(deltaIC(fit1, fit2, fit3, criterion = c(\"DIC\")))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"cv-and-spde-parameters-for-model-2","dir":"Articles","previous_headings":"Factor covariates","what":"CV and SPDE parameters for Model 2","title":"LGCPs - Spatial covariates","text":"going Model fit2. Lets look spatial distribution coefficient variation  Plot vegetation “fixed effect” posteriors. First get names - $marginals.random$vegetation fitted object, contains fixed effect marginal distribution data  Use spde.posterior( ) obtain plot SPDE parameter posteriors Matern correlation covariance functions model.","code":"ggplot() +   gg(int2, aes(fill = sd / mean), geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests) flist <- vector(\"list\", NROW(fit2$summary.random$vegetation)) for (i in seq_along(flist)) flist[[i]] <- plot(fit2, \"vegetation\", index = i) multiplot(plotlist = flist, cols = 3) spde.range <- spde.posterior(fit2, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit2, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"continuous-covariates","dir":"Articles","previous_headings":"","what":"Continuous covariates","title":"LGCPs - Spatial covariates","text":"Now lets try model elevation (continuous) explanatory variable. (First centre elevations stable fitting.)  elevation variable class ‘SpatRaster’, can handled way vegetation covariate, automatic evaluation via eval_spatial() method. However, since cases data may stored differently, methods needed access stored values, ’s post-processing done. cases, can define function knows evaluate covariate arbitrary points survey region, call function component definition. method eval_spatial() method handles automatically, supports terra SpatRaster sf geometry points objects, mismatching coordinate systems well. following evaluator example function, add infilling missing values post-processing step. brevity going consider models elevation , elevation SPDE, SPDE . just fit one elevation SPDE. create model pass lgcp thus: Note elevation effect defined. alternatively use terra grid object directly (causing inlabru automatically call eval_spatial()), like vegetation case: specified like whereas special function method specify covariate like : applications can use automatic method, special function method included example handle complex cases. also now include intercept term model. model fitted usual way: Summary model selection Predict plot density  Now look elevation SPDE effects space. Leave Intercept swamps spatial effects elevation SPDE plots interested comparing effects elevation SPDE. First need predict linear predictor scale. code , similar used vegetation factor variable, produces plots want.  might also want look posteriors fixed effects SPDE. Adapt code used vegetation factor .  Plot SPDE parameter posteriors Matern correlation covariance functions model.   Also estimate abundance. data.frame second call leads inclusion N prediction object, easier plotting. Plot way previous practicals","code":"elev <- gcov$elevation elev <- elev - mean(terra::values(elev), na.rm = TRUE)  ggplot() +   gg(elev, geom = \"tile\") +   gg(boundary, alpha = 0) # Note: this method is usually not needed; the automatic invocation of # `eval_spatial()` method by the component input evaluator is usually # sufficient. f.elev <- function(where) {   # Extract the values   v <- eval_spatial(elev, where, layer = \"elevation\")   # Fill in missing values; this example would work for   # SpatialPixelsDataFrame data   # if (any(is.na(v))) {   #   v <- bru_fill_missing(elev, where, v)   # }   v } matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.1, 0.01) )  ecomp <- geometry ~ elev(f.elev(.data.), model = \"linear\") +   mySmooth(geometry, model = matern) + Intercept(1) elev(elev, model = \"factor_full\") elev(f.elev(.data.), model = \"linear\") efit <- lgcp(ecomp, nests, samplers = boundary, domain = list(geometry = mesh)) summary(efit) #> inlabru version: 2.12.0.9016 #> INLA version: 25.05.18-1 #> Components: #> elev: main = linear(f.elev(.data.)), group = exchangeable(1L), replicate = iid(1L), NULL #> mySmooth: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Observation models: #>   Family: 'cp' #>     Tag: '' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: geometry ~ . #>     Additive/Linear: TRUE/TRUE #>     Used components: effects[elev, mySmooth, Intercept], latent[] #> Time used: #>     Pre = 0.38, Running = 4.37, Post = 0.269, Total = 5.01  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode kld #> elev      0.004 0.001      0.002    0.004      0.006 0.004   0 #> Intercept 1.127 0.478      0.155    1.137      2.038 1.137   0 #>  #> Random effects: #>   Name     Model #>     mySmooth SPDE2 model #>  #> Model hyperparameters: #>                    mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for mySmooth 1.76 0.217      1.376     1.75       2.23 1.713 #> Stdev for mySmooth 1.00 0.085      0.848     1.00       1.18 0.995 #>  #> Deviance Information Criterion (DIC) ...............: 520.85 #> Deviance Information Criterion (DIC, saturated) ....: 520.02 #> Effective number of parameters .....................: -825.54 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1603.67 #> Effective number of parameters .................: 153.46 #>  #> Marginal log-Likelihood:  -1254.95  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') deltaIC(fit1, fit2, fit3, efit) #>   Model       DIC Delta.DIC #> 1  fit1 -562.5418     0.000 #> 2  efit  520.8480  1083.390 #> 3  fit3  524.7293  1087.271 #> 4  fit2  618.8318  1181.374 e.pred <- predict(   efit,   pred.df,   ~ list(     int = exp(mySmooth + elev + Intercept),     int.log = mySmooth + elev + Intercept   ) )  p1 <- ggplot() +   gg(e.pred$int, aes(fill = log(sd)), geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") p2 <- ggplot() +   gg(e.pred$int.log, aes(fill = exp(mean + sd^2 / 2)), geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") library(patchwork) p1 | p2 e.lp <- predict(   efit,   pred.df,   ~ list(     smooth_elev = mySmooth + elev,     elev = elev,     smooth = mySmooth   ) ) lprange <- range(e.lp$smooth_elev$mean, e.lp$elev$mean, e.lp$smooth$mean)  library(RColorBrewer) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.e.lp <- ggplot() +   gg(e.lp$smooth_elev, mask = boundary, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE + elevation\")  plot.e.lp.spde <- ggplot() +   gg(e.lp$smooth, mask = boundary, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE\")  plot.e.lp.elev <- ggplot() +   gg(e.lp$elev, mask = boundary, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"elevation\")  multiplot(plot.e.lp,   plot.e.lp.spde,   plot.e.lp.elev,   cols = 3 ) LambdaE <- predict(   efit,   fm_int(mesh, boundary),   ~ sum(weight * exp(Intercept + elev + mySmooth)) ) LambdaE #>      mean       sd   q0.025     q0.5 q0.975   median sd.mc_std_err #> 1 668.651 27.24863 622.3369 667.1175 718.47 667.1175      2.032972 #>   mean.mc_std_err #> 1        3.131458 flist <- vector(\"list\", NROW(efit$summary.fixed)) for (i in seq_along(flist)) {   flist[[i]] <- plot(efit, rownames(efit$summary.fixed)[i]) } multiplot(plotlist = flist, cols = 2) spde.range <- spde.posterior(efit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(efit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot) Lambda <- predict(   efit, fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + elev + Intercept)) ) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 675.4717 24.60605 636.1228 674.8819 718.6384 674.8819      1.976951 #>   mean.mc_std_err #> 1        2.855995  Nest.e <- predict(   efit,   fm_int(mesh, boundary),   ~ data.frame(     N = 200:1000,     density = dpois(200:1000,       lambda = sum(weight * exp(mySmooth + elev + Intercept))     )   ),   n.samples = 2000 ) Nest.e$plugin_estimate <- dpois(Nest.e$N, lambda = Lambda$median) ggplot(data = Nest.e) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"non-spatial-evaluation-of-the-covariate-effect","dir":"Articles","previous_headings":"Continuous covariates","what":"Non-spatial evaluation of the covariate effect","title":"LGCPs - Spatial covariates","text":"previous examples posterior prediction focused spatial prediction. also possible evaluate effect covariate directly, bypassing component definition input. done adding suffix _eval() end component name predictor expression, supplying data sufficient evaluating , supplying data needed input arguments function, see bru_component_eval(). Note backwards version support, starting version 2.2.8 Prior version 2.8.0, feature required setting include argument character(0) disable normal component evaluation components. version 2.8.0, inlabru automatically detects model components used prediction expression, including use component _eval() calls, making include argument unnecessary. version 2.11.0, include, exclude, include_latent arguments deprecated favour used argument takes input generated bru_used(), deprecation warning generated version 2.12.0.9003. Since elevation effect model linear, resulting plot isn’t interesting, method can applied non-linear effects (e.g. “rw2”) well, combined general R expressions.","code":"elev.pred <- predict(   efit,   data.frame(elevation = seq(0, 100, length.out = 1000)),   formula = ~ elev_eval(elevation)   # include = character(0) # Not needed from version 2.8.0 )  ggplot(elev.pred) +   geom_line(aes(elevation, mean)) +   geom_ribbon(     aes(elevation,       ymin = q0.025,       ymax = q0.975     ),     alpha = 0.2   ) +   geom_ribbon(     aes(elevation,       ymin = mean - 1 * sd,       ymax = mean + 1 * sd     ),     alpha = 0.2   )"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_covars.html","id":"a-1d-example","dir":"Articles","previous_headings":"","what":"A 1D Example","title":"LGCPs - Spatial covariates","text":"Try fitting 1-dimensional model point data inlabru dataset Poisson2_1D. comes covariate function called cov2_1D. Try reproduce plot (used lectures) showing effects Intercept + z SPDE. (may find helpful build model fitted previous practical, adding covariate model specification.)","code":"data(Poisson2_1D) x <- seq(0, 55, length.out = 50) mesh <- fm_mesh_1d(x, degree = 2, boundary = \"free\")  process_model <- inla.spde2.pcmatern(   mesh,   prior.sigma = c(1, 0.01),   prior.range = c(5, 0.01),   constr = TRUE ) comp <- x ~   z(cov2_1D(x), model = \"linear\") +   smooth(x, model = process_model) +   Intercept(1)  fitcov1D <- lgcp(comp,   pts2,   domain = list(x = mesh),   samplers = tibble::tibble(x = cbind(0, 55)) ) pr.df <- data.frame(x = x) prcov1D <- predict(   fitcov1D,   pr.df,   ~ list(     Intensity = exp(z + smooth + Intercept),     z = exp(z + Intercept),     smooth = exp(smooth)   ),   n.samples = 2000 )  ggplot() +   gg(prcov1D$Intensity,     aes(colour = \"Intensity\", fill = \"Intensity\"),     alpha = 0.2,     lwd = 1.25   ) +   gg(prcov1D$smooth,     aes(colour = \"Smooth\", fill = \"Smooth\"),     alpha = 0.2,     lwd = 1.25   ) +   gg(prcov1D$z,     aes(colour = \"z-effect\", fill = \"z-effect\"),     alpha = 0.2,     lwd = 1.25   ) +   geom_line(aes(x, lambda2_1D(x), colour = \"True intensity\"), lwd = 1.25) +   geom_point(data = pts2, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +   xlab(quote(bold(s))) +   ylab(quote(hat(lambda)(bold(s)) ~ ~\"and its components\")) +   guides(colour = guide_legend(\"Quantity\"), fill = \"none\")"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_spatiotemporal.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - An example in space and time","text":"vignette going working dataset obtained R package MRSea. set LGCP spatio-temporal SPDE model estimate species distribution.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_spatiotemporal.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in space and time","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_spatiotemporal.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - An example in space and time","text":"Load dataset, coordinates UTM kilometres: points (representing animals) sampling regions dataset associated season. Let’s look observed points sampling regions seasons:","code":"mrsea <- inlabru::mrsea ggplot() +   geom_fm(data = mrsea$mesh) +   gg(mrsea$boundary) +   gg(mrsea$samplers) +   gg(mrsea$points, size = 0.5) +   facet_wrap(~season) +   ggtitle(\"MRSea observation seasons\")"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_spatiotemporal.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting the model","title":"LGCPs - An example in space and time","text":"Fit LGCP model locations animals. example employ spatio-temporal SPDE. Note group ngroup parameters employed let SPDE model know name time dimension (season) total number distinct points time. point process likelihood constructed lgcp() function, wrapper around bru_obs(..., model = \"cp\") bru() functions. Like ordinary spatial point process models, samplers argument specifies observation region/set, case combinations spatial lines seasons. domain argument specifies spatio-temporal function space use constructing numerical integration scheme needed point process likelihood evaluation. Predict plot intensity seasons:","code":"matern <- inla.spde2.pcmatern(mrsea$mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(10, 0.01) )  cmp <- ~ Intercept(1) +   mySmooth(     geometry,     model = matern,     group = season,     ngroup = 4   )  fit <- bru(   cmp,   bru_obs(     geometry + season ~ .,     family = \"cp\",     data = mrsea$points,     samplers = mrsea$samplers,     domain = list(       geometry = mrsea$mesh,       season = seq_len(4)     )   ) ) ppxl <- fm_pixels(mrsea$mesh, mask = mrsea$boundary, format = \"sf\") ppxl_all <- fm_cprod(ppxl, data.frame(season = seq_len(4)))  lambda1 <- predict(   fit,   ppxl_all,   ~ data.frame(season = season, lambda = exp(mySmooth + Intercept)) ) pl1 <- ggplot() +   gg(lambda1, geom = \"tile\", aes(fill = q0.5)) +   gg(mrsea$points, size = 0.3) +   facet_wrap(~season) +   coord_sf() pl1"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/lgcp_2d_spatiotemporal.html","id":"integration-points","dir":"Articles","previous_headings":"","what":"Integration points","title":"LGCPs - An example in space and time","text":"inlabru point process model, lgcp() bru_obs(..., model = \"cp\"), knows construct numerical integration scheme LGCP likelihood. see happens internally, can also call internal functions directly see integration scheme look like, using fm_int() function domain samplers arguments previous lgcp() call. Note omitting season dimension domain lead aggregation sampling regions time. Plot integration points:","code":"ips <- fm_int(   domain = list(geometry = mrsea$mesh, season = 1:4),   samplers = mrsea$samplers ) ggplot() +   geom_fm(data = mrsea$mesh) +   gg(ips, aes(size = weight)) +   scale_size_area(max_size = 1) +   facet_wrap(~season)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"The Piemonte dataset example","text":"vignette illustrate fit spacetime models Lindgren et al. (2024), see [SORT vol. 48, . 1, pp. 3-66] related code, data analysed Cameletti et al. (2013). perform use Bayesian paradigm theINLA package, using features provided inlabru package facilitate coding.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"the-packages-and-setup","dir":"Articles","previous_headings":"Introduction","what":"The packages and setup","title":"The Piemonte dataset example","text":"start loading required packages visualizations, ggplot2 patchwork packages. ask return WAIC, DIC CPO","code":"library(ggplot2) library(patchwork) library(INLA) #> Loading required package: Matrix #> This is INLA_25.05.18-1 built 2025-05-17 15:45:06 UTC. #>  - See www.r-inla.org/contact-us for how to get help. #>  - List available models/likelihoods/etc with inla.list.models() #>  - Use inla.doc(<NAME>) to access documentation library(INLAspacetime) #> Loading required package: fmesher #> see more on https://eliaskrainski.github.io/INLAspacetime library(inlabru) library(fmesher) ctrc <- list(   waic = TRUE,   dic = TRUE,   cpo = TRUE )"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"getting-the-dataset","dir":"Articles","previous_headings":"Introduction","what":"Getting the dataset","title":"The Piemonte dataset example","text":"use dataset analysed Cameletti et al. (2013), can downloaded follows. First, set filenames Download read borders file, station coordinates, observation data cache directory, e.g. cache_path <- \"nonseparable_spacetime_cache\": Inspect dataset Prepare time used (alternatively, different time mapping can used) Standardize covariates used data analysis define dataset including needed information outcome log PM10, used Cameletti et al. (2013).","code":"u0 <- paste0(   \"http://inla.r-inla-download.org/\",   \"r-inla.org/case-studies/Cameletti2012/\" ) coofl <- \"coordinates.csv\" datafl <- \"Piemonte_data_byday.csv\" bordersfl <- \"Piemonte_borders.csv\"  get_file <- function(url_root, file, cache_path) {   dir.create(cache_path, recursive = TRUE)   file_path <- file.path(cache_path, file)   if (!file.exists(file_path)) {     download.file(paste0(url_root, file), file_path)   }   read.csv(file_path) } dim(pborders <- get_file(u0, bordersfl, cache_path)) #> [1] 27821     2 dim(locs <- get_file(u0, coofl, cache_path)) #> [1] 24  3 dim(pdata <- get_file(u0, datafl, cache_path)) #> [1] 4368   11 head(pdata) #>   Station.ID     Date     A   UTMX    UTMY   WS   TEMP   HMIX PREC   EMI PM10 #> 1          1 01/10/05  95.2 469.45 4972.85 0.90 288.81 1294.6    0 26.05   28 #> 2          2 01/10/05 164.1 423.48 4950.69 0.82 288.67 1139.8    0 18.74   22 #> 3          3 01/10/05 242.9 490.71 4948.86 0.96 287.44 1404.0    0  6.28   17 #> 4          4 01/10/05 149.9 437.36 4973.34 1.17 288.63 1042.4    0 29.35   25 #> 5          5 01/10/05 405.0 426.44 5045.66 0.60 287.63 1038.7    0 32.19   20 #> 6          6 01/10/05 257.5 394.60 5001.18 1.02 288.59 1048.3    0 34.24   41 range(pdata$Date <- as.Date(pdata$Date, \"%d/%m/%y\")) #> [1] \"2005-10-01\" \"2006-03-31\" pdata$time <- as.integer(difftime(   pdata$Date, min(pdata$Date),   units = \"days\" )) + 1 ### prepare the covariates xnames <- c(\"A\", \"WS\", \"TEMP\", \"HMIX\", \"PREC\", \"EMI\") xmean <- colMeans(pdata[, xnames]) xsd <- sapply(pdata[xnames], sd)  ### prepare the data (st loc, scale covariates and log PM10) dataf <- data.frame(pdata[c(\"UTMX\", \"UTMY\", \"time\")],   scale(pdata[xnames], xmean, xsd),   y = log(pdata$PM10) ) str(dataf) #> 'data.frame':    4368 obs. of  10 variables: #>  $ UTMX: num  469 423 491 437 426 ... #>  $ UTMY: num  4973 4951 4949 4973 5046 ... #>  $ time: num  1 1 1 1 1 1 1 1 1 1 ... #>  $ A   : num  -1.3956 -0.7564 -0.0254 -0.8881 1.4785 ... #>  $ WS  : num  -0.0777 -0.2319 0.038 0.4429 -0.6561 ... #>  $ TEMP: num  2.1 2.07 1.82 2.06 1.86 ... #>  $ HMIX: num  2.18 1.69 2.53 1.38 1.37 ... #>  $ PREC: num  -0.29 -0.29 -0.29 -0.29 -0.29 ... #>  $ EMI : num  -0.1753 -0.3454 -0.6353 -0.0985 -0.0324 ... #>  $ y   : num  3.33 3.09 2.83 3.22 3 ..."},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"the-data-model-definition","dir":"Articles","previous_headings":"","what":"The data model definition","title":"The Piemonte dataset example","text":"consider following linear mixed model outcome \\[ \\mathbf{y} = \\mathbf{W}\\mathbf{\\beta} + \\mathbf{}\\mathbf{u} + \\mathbf{e} \\] \\(\\beta\\) fixed effects, regression coefficients including intercept, matrix covariates \\(\\mathbf{W}\\), \\(\\mathbf{u}\\) spatio-temporal random effect matrix \\(\\mathbf{}\\) projector matrix discretized domain data. spatio-temporal random effect \\(\\mathbf{u}\\) defined continuous spacetime domain discretized considering meshes time space. difference Cameletti et al. (2013) now use models Lindgren et al. (2024) \\(\\mathbf{u}\\). Define temporal mesh, knot spaced h, h = 1 means one per day. Define spatial mesh, used Cameletti et al. (2013). Visualize spatial mesh, border locations.  set prior likelihood precision considering PC-prior, Simpson et al. (2017), following probabilistic statements: P(\\(\\sigma_e > U_{\\sigma_e}\\)) = \\(\\alpha_{\\sigma_e}\\), using \\(U_{\\sigma_e}\\) = 1 \\(\\alpha_{\\sigma_e} = 0.05\\). inlabru can define observation/likelihood model bru_obs() function use fitting models different linear predictors later. linear predictor, right-rand side formula, can defined using expression models going fit ","code":"nt <- max(pdata$time) h <- 10 tmesh <- fm_mesh_1d(   loc = seq(1, nt + h / 2, h),   degree = 1 ) tmesh$n #> [1] 19 smesh <- fm_mesh_2d(   cbind(locs[, c(\"UTMX\", \"UTMY\")]),   loc.domain = pborders,   max.edge = c(50, 300),   offset = c(10, 140),   cutoff = 5,   min.angle = c(26, 21) ) smesh$n #> [1] 142 ggplot() +   theme_minimal() +   geom_fm(data = smesh) +   geom_polygon(     data = pborders, aes(x = UTM_X, y = UTM_Y),     fill = NA, color = \"green4\", size = 1   ) +   geom_point(aes(UTMX, UTMY), data = locs, col = \"blue\") lkprec <- list(   prec = list(prior = \"pcprec\", param = c(1, 0.05)) ) lhood <- bru_obs(   formula = y ~ .,   family = \"gaussian\",   control.family = list(     hyper = lkprec   ),   data = dataf ) M <- ~ -1 + Intercept(1) + A + WS + TEMP + HMIX + PREC + EMI +   field(     list(       space = cbind(UTMX, UTMY),       time = time     ),     model = stmodel   )"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"the-spacetime-models","dir":"Articles","previous_headings":"","what":"The spacetime models","title":"The Piemonte dataset example","text":"implementation spacetime model uses cgeneric interface INLA, see documentation details. Therefore C code mainly build precision matrix compute model parameter priors compiled static library. code included INLAspacetime package also copied INLA package compiled compilers order avoid possible mismatches. order use , define matrices vectors needed, including prior parameter definitions. class models Lindgren et al. (2024) spatial range, temporal range marginal standard deviation parameters. consider PC-prior, Fuglstad et al. (2017), parameters defined probability statements: P(\\(r_s<U_{r_s}\\))=\\(\\alpha_{r_s}\\), P(\\(r_t<U_{r_t}\\))=\\(\\alpha_{r_t}\\) P(\\(\\sigma<U_{\\sigma}\\))=\\(\\alpha_{\\sigma}\\). consider \\(U_{r_s}=100\\), \\(U_{r_t}=5\\) \\(U_{\\sigma}=2\\). \\(\\alpha_{r_s}=\\alpha_{r_t}=\\alpha_{\\sigma}=0.05\\) selection one models Lindgren et al. (2024) chosing \\(\\alpha_t\\), \\(\\alpha_s\\) \\(\\alpha_e\\) integer numbers. start considering model \\(\\alpha_t=1\\), \\(\\alpha_s=0\\) \\(\\alpha_t=2\\), model separable spatio-temporal covariance, fit models later.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"defining-a-particular-model","dir":"Articles","previous_headings":"The spacetime models","what":"Defining a particular model","title":"The Piemonte dataset example","text":"define object needed use function stModel.define() model selected considering values \\(\\alpha_t\\), \\(\\alpha_s\\) \\(\\alpha_e\\) collapsed. order illustrate done, can set overall integrate--zero constraint, needed helps model components identification. uses weights based mesh node volumes, temporal spatial meshes. can set automatically defining model adding constr = TRUE. Initial values hyper-parameters help fit models less computing time. also important consider light dataset parameter scale. example, consider spatial domain within box around \\(203.7\\) \\(266.5\\) kilometres, already building mesh setting prior \\(r_s\\). can set initial values log parameters take less iterations converge: code fit model inlabru Summary posterior marginal distributions fixed effects hyperparameters, transform posterior marginal distributions model hyperparameters ones computed internal scale, \\(\\log(1/\\sigma^2_e)\\), \\(\\log(r_s)\\), \\(\\log(r_t)\\) \\(\\log(\\sigma)\\), user scale parametrization, \\(\\sigma_e\\), \\(r_s\\), \\(r_t\\) \\(\\sigma\\), respectively. compute show summary However, better look posterior marginal , visualize later. model fitted Cameletti et al. (2013) includes two covariates setup model discrete temporal domain temporal correlation modeled first order autoregression parameter \\(\\rho\\). fitted model defined considering continuous temporal domain range parameter \\(r_s\\). However, first order autocorrelation taken \\(\\rho = \\exp(-h\\sqrt{8\\nu}/r_s)\\), \\(h\\) temporal resolution used temporal mesh \\(\\nu\\) equal \\(0.5\\) fitted model. can compare results Table 3 Cameletti et al. (2013) ","code":"model <- \"102\" stmodel <- stModel.define(   smesh, tmesh, model,   control.priors = list(     prs = c(150, 0.05),     prt = c(10, 0.05),     psigma = c(5, 0.05)   ),   constr = TRUE ) theta.ini <- c(4, 7, 7, 1) fit102 <-   bru(M,     lhood,     options = list(       control.mode = list(theta = theta.ini, restart = TRUE),       control.compute = ctrc     )   ) fit102$summary.fixed[, c(1, 2, 3, 5)] #>                  mean          sd  0.025quant  0.975quant #> Intercept  3.65238559 0.552429933  2.55864054  4.74812298 #> A         -0.15585802 0.093586287 -0.34125299  0.02951614 #> WS        -0.12547654 0.008419182 -0.14198642 -0.10896633 #> TEMP       0.02522772 0.019372417 -0.01276320  0.06321554 #> HMIX      -0.11639106 0.009903560 -0.13581105 -0.09696919 #> PREC      -0.14862494 0.007416478 -0.16316907 -0.13408157 #> EMI        0.05708936 0.022410769  0.01348511  0.10150065 post.h <- list(   sigma_e = inla.tmarginal(     function(x) exp(-x / 2),     fit102$internal.marginals.hyperpar[[1]]   ),   range_s = inla.tmarginal(     function(x) exp(x),     fit102$internal.marginals.hyperpar[[2]]   ),   range_t = inla.tmarginal(     function(x) exp(x),     fit102$internal.marginals.hyperpar[[3]]   ),   sigma_u = inla.tmarginal(     function(x) exp(x),     fit102$internal.marginals.hyperpar[[4]]   ) ) shyper <- t(sapply(post.h, function(m) {   unlist(inla.zmarginal(m, silent = TRUE)) })) shyper[, c(1, 2, 3, 7)] #>                mean           sd  quant0.025   quant0.975 #> sigma_e   0.3839449 4.361368e-03   0.3754984    0.3926268 #> range_s 552.3122820 6.420467e+01 438.8633289  690.7194209 #> range_t 677.6890686 2.153839e+02 351.9205574 1190.8092398 #> sigma_u   1.6571996 2.619478e-01   1.2047595    2.2315043 c(shyper[c(1, 4, 2), 1],   a = exp(-h * sqrt(8 * 0.5) / shyper[3, 1]) ) #>     sigma_e     sigma_u     range_s           a  #>   0.3839449   1.6571996 552.3122820   0.9709192"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"comparing-different-models","dir":"Articles","previous_headings":"","what":"Comparing different models","title":"The Piemonte dataset example","text":"now fit model \\(121\\) \\(u\\) well, use code building model matrices use code fitting follows join fits list object make easier working computing time model fit number fn-calls optimization posterior mode parameter model (internal scale) compute posterior marginal distribution hyper-parameters user-interpretable scale, like first model, Join make visualization easier  comparison model parameters \\(\\mathbf{u}\\) different models done light covariance functions illustrated Lindgren et al. (2024). fitted \\(\\sigma_e\\) different models comparable can see considering model \\(121\\) \\(\\mathbf{u}\\), posterior marginal concentrated values lower considering model \\(102\\). can look posterior mean \\(u\\) models see model ‘121’ wider spread.  can also check fitting statistics DIC, WAIC, negative log probability ordinates (LPO) cross-validated version (LCPO), summarized mean.","code":"model <- \"121\" stmodel <- stModel.define(   smesh, tmesh, model,   control.priors = list(     prs = c(150, 0.05),     prt = c(10, 0.05),     psigma = c(5, 0.05)   ),   constr = TRUE ) fit121 <-   bru(M,     lhood,     options = list(       control.mode = list(theta = theta.ini, restart = TRUE),       control.compute = ctrc     )   ) results <- list(\"u102\" = fit102, \"u121\" = fit121) sapply(results, function(r) r$cpu.used) #>               u102       u121 #> Pre      0.5681772  0.2897706 #> Running 14.2543929 45.0364482 #> Post     0.9194994  0.3037057 #> Total   15.7420695 45.6299245 sapply(results, function(r) r$misc$nfunc) #> u102 u121  #>  321  656 sapply(results, function(r) r$mode$theta) #>                                                  u102      u121 #> Log precision for the Gaussian observations 1.9152099  1.904720 #> Theta1 for field                            6.2998720  8.257806 #> Theta2 for field                            6.4642249 15.234416 #> Theta3 for field                            0.4888425  2.722212 posts.h2 <- lapply(1:2, function(m) vector(\"list\", 4L)) for (m in 1:2) {   posts.h2[[m]]$sigma_e <-     data.frame(       parameter = \"sigma_e\",       inla.tmarginal(         function(x) exp(-x / 2),         results[[m]]$internal.marginals.hyperpar[[1]]       )     )   for (p in 2:4) {     posts.h2[[m]][[p]] <-       data.frame(         parameter = c(NA, \"range_s\", \"range_t\", \"sigma_u\")[p],         inla.tmarginal(           function(x) exp(x),           results[[m]]$internal.marginals.hyperpar[[p]]         )       )   } } posts.df <- rbind(   data.frame(model = \"102\", do.call(rbind, posts.h2[[1]])),   data.frame(model = \"121\", do.call(rbind, posts.h2[[2]])) )  ggplot(posts.df) +   geom_line(aes(x = x, y = y, group = model, color = model)) +   ylab(\"Density\") +   xlab(\"\") +   facet_wrap(~parameter, scales = \"free\") par(mfrow = c(1, 1), mar = c(3, 3, 0, 0.0), mgp = c(2, 1, 0)) uu.hist <- lapply(results, function(r) {   hist(r$summary.random$field$mean,     -60:60 / 20,     plot = FALSE   ) }) ylm <- range(uu.hist[[1]]$count, uu.hist[[2]]$count) plot(uu.hist[[1]],   ylim = ylm,   col = rgb(1, 0.1, 0.1, 1.0), border = FALSE,   xlab = \"u\", main = \"\" ) plot(uu.hist[[2]], add = TRUE, col = rgb(0.1, 0.1, 1, 0.5), border = FALSE) legend(\"topleft\", c(\"separable\", \"non-separable\"),   fill = rgb(c(1, 0.1), 0.1, c(0.1, 1), c(1, 0.5)),   border = \"transparent\", bty = \"n\" ) t(sapply(results, function(r) {   c(     DIC = mean(r$dic$local.dic, na.rm = TRUE),     WAIC = mean(r$waic$local.waic, na.rm = TRUE),     LPO = -mean(log(r$po$po), na.rm = TRUE),     LCPO = -mean(log(r$cpo$cpo), na.rm = TRUE)   ) })) #>            DIC      WAIC       LPO      LCPO #> u102 0.9580639 0.9590567 0.4426017 0.4810287 #> u121 0.9743453 0.9737106 0.4455675 0.4885247"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/nonseparable_spacetime.html","id":"the-automatic-group-leave-out-cross-validation","dir":"Articles","previous_headings":"","what":"The automatic group-leave-out cross validation","title":"The Piemonte dataset example","text":"One may interested evaluating model prediction. leave-one-strategy already available INLA since several years ago, see Held, Schrodle, Rue (2010) details. Recently, automatic group cross validation strategy implemented, see Liu Rue (2023) details. can inspect detected observations posterior linear predictor correlated one, including . 100th observation model “102” result model “121” intersect always , model setup used. can check observations dataset found locations nearby time. can compute negative mean log score lower number better","code":"g5cv <- lapply(   results, inla.group.cv,   num.level.sets = 5,   strategy = \"posterior\", size.max = 50 ) g5cv$u102$group[[100]] #> $idx #> [1]  52  76 100 124 148 #>  #> $corr #> [1] 0.9673220 0.9358742 1.0000000 0.9870395 0.9302908 g5cv$u121$group[[100]] #> $idx #> [1]  52  76 100 124 148 #>  #> $corr #> [1] 0.9704981 0.9469381 1.0000000 0.9883623 0.9381322 dataf[g5cv$u102$group[[100]]$idx, ] #>       UTMX    UTMY time          A        WS     TEMP       HMIX       PREC #> 52  437.36 4973.34    3 -0.8881265 0.9826878 1.077344 -0.6959771 1.94505331 #> 76  437.36 4973.34    4 -0.8881265 0.6742163 1.297701  0.9479287 3.70037355 #> 100 437.36 4973.34    5 -0.8881265 0.7706136 1.441935  0.2530248 0.16426526 #> 124 437.36 4973.34    6 -0.8881265 0.7513342 1.618220  1.0845756 0.03692618 #> 148 437.36 4973.34    7 -0.8881265 1.9273816 1.648269 -0.6259302 1.71976109 #>             EMI        y #> 52  -0.01821338 2.564949 #> 76  -0.01542101 2.708050 #> 100  0.01622576 2.890372 #> 124  0.02599903 2.995732 #> 148  0.08114818 2.944439 sapply(g5cv, function(r) -mean(log(r$cv), na.rm = TRUE)) #>      u102      u121  #> 0.5216302 0.5376016"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_1d.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"Random Fields in One Dimension","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(mgcv) library(ggplot2) library(fmesher) library(patchwork) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_1d.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"Random Fields in One Dimension","text":"Load data rename countdata object cd (just ‘cd’ less type ‘countdata2’.): Take look count data.  Tip: RStudio > Help > Cheatsheets > Data visualisation ggplot2 useful reference ggplot2 syntax.","code":"data(Poisson2_1D) cd <- countdata2 cd #>            x count exposure #> 1   2.319888     9 4.639776 #> 2   6.959664    13 4.639776 #> 3  11.599439    11 4.639776 #> 4  16.239215    22 4.639776 #> 5  20.878991    20 4.639776 #> 6  25.518766    19 4.639776 #> 7  30.158542    16 4.639776 #> 8  34.798318     8 4.639776 #> 9  39.438093     4 4.639776 #> 10 44.077869     4 4.639776 #> 11 48.717645     4 4.639776 ggplot(cd) +   geom_point(aes(x, y = count)) +   ylim(0, max(cd$count))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_1d.html","id":"fitting-a-generalised-additive-model-gam","dir":"Articles","previous_headings":"","what":"Fitting a Generalised Additive Model (GAM)","title":"Random Fields in One Dimension","text":"’re familiar GAMs syntax gam don’t worry, point just provide something can compare inlabru model fit. term s(x,k=10) just specifies nonparametric smooth function fitted data, 10 degrees freedom (df). (larger df, wiggly fitted curve (recall lecture effect spline methods defined, without discretisation dependent penalty); gam selects ‘best’ df.) Notice use offset= incorporate variable exposure cd size bin count made. can look fitted model using summary( ) want , need understand output, code makes predictions immediately familiar GAMs. Make prediction data frame, get predictions add data frame First make vectors x-values associated (equal) exposures: put data frame: predict Plotting fit data using ggplot2 commands give plot shown ","code":"fit2.gam <- gam(count ~ s(x, k = 10) + offset(log(exposure)),   family = poisson(),   data = cd ) summary(fit2.gam) xs <- seq(0, 55, length = 100) exposures <- rep(cd$exposure[1], 100) dat4pred <- data.frame(x = xs, exposure = exposures) pred2.gam <- predict(fit2.gam, newdata = dat4pred, type = \"response\") # add column for prediction in data frame: dat4pred2 <- cbind(dat4pred, gam = pred2.gam) ggplot(dat4pred2) +   geom_line(aes(x = x, y = gam), lty = 2) +   ylim(0, max(dat4pred2$gam, cd$count)) +   geom_point(aes(x = x, y = count), cd)"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_1d.html","id":"fitting-an-spde-model-with-inlabru","dir":"Articles","previous_headings":"","what":"Fitting an SPDE model with inlabru","title":"Random Fields in One Dimension","text":"Make mesh. avoid boundary effects region interest, let mesh extend outside data range. … see mesh knots : can also draw basis functions:  special cases, one can control knots boundary conditions. Normally, just need ensure enough flexibility represent intended Gaussian process dependence structure, adding needless computations.","code":"x <- seq(-10, 65, by = 5) # this sets mesh points - try others if you like (mesh1D <- fm_mesh_1d(x, degree = 2, boundary = \"free\")) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  16 #>   Interval:  (-10,  65) #>   Boundary:  (free, free) #>   B-spline degree:   2 #>   Basis d.o.f.:  17 ggplot() +   gg(mesh1D) ggplot() +   geom_fm(data = mesh1D) (mesh <- fm_mesh_1d(c(1, 2, 3, 4, 6),   boundary = c(\"neumann\", \"free\"),   degree = 2 )) #> fm_mesh_1d object: #>   Manifold:  R1 #>   #{knots}:  5 #>   Interval:  (1, 6) #>   Boundary:  (neumann, free) #>   B-spline degree:   2 #>   Basis d.o.f.:  5 ggplot() +   geom_fm(data = mesh, xlim = c(0, 7))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_1d.html","id":"using-function-bru-to-fit-to-count-data","dir":"Articles","previous_headings":"Fitting an SPDE model with inlabru","what":"Using function bru( ) to fit to count data","title":"Random Fields in One Dimension","text":"need specify model components model formula order fit . can done inside call bru( ) bit messy, ’ll store comp first pass bru( ). response variable data frame cd called count model specification needs left ~. add intercept component + Intercept(1) right hand side (models use intercepts), want fit Gaussian random field (GRF), must GRF specification. inlabru GRF specification function, allows GRF calculated point space inlabru calculations. user gets name GRF function. syntax myname(input, model= ...), : ‘myname’ whatever want call GRF (called field ); input specifies coordinates GRF SPDE ‘lives’. working one dimension, called dimension x set data set. model= designates type effect, SPDE model object INLA function inla.spde2.pcmatern( ), requires mesh passed , pass 1D mesh created , mesh1D. models sums model components, don’t need specify full predictor formula. Instead, can provide name output left ~ component specification, “.” right hand side, cause add components (unless subset selected via used argument bru_obs()). Predict values x points used mesh (data argument must data frame, see ?predict.bru): Let’s plot compare fitted model true model. expected counts true model stored variable E_nc2 comes dataset Poisson2_1D. ease use plotting ggplot2 (needs data frame), create data frame call true.lambda, containing x- y variables shown . Given inlabru predictions always intensity function scale, understand divide count cd$exposure? (due course allow predictions count scale well.) ggplot2 commands generate plot shown . shows true intensities short horizontal blue lines, observed intensities black dots, fitted intensity function red curve, 95% credible intervals shown light red band curve.  Compare inlabru fit gam fit:","code":"the_spde <- inla.spde2.pcmatern(mesh1D,   prior.range = c(1, 0.01),   prior.sigma = c(1, 0.01) )  comp <- ~ field(x, model = the_spde) + Intercept(1, prec.linear = 1 / 2^2)  fit2.bru <- bru(   comp,   bru_obs(     count ~ .,     data = cd,     family = \"poisson\",     E = exposure   ) )  summary(fit2.bru) #> inlabru version: 2.12.0.9016 #> INLA version: 25.05.18-1 #> Components: #> field: main = spde(x), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Observation models: #>   Family: 'poisson' #>     Tag: '' #>     Data class: 'data.frame' #>     Response class: 'integer' #>     Predictor: count ~ . #>     Additive/Linear: TRUE/TRUE #>     Used components: effects[field, Intercept], latent[] #> Time used: #>     Pre = 0.435, Running = 0.379, Post = 0.0797, Total = 0.894  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode kld #> Intercept 0.631 0.469      -0.41    0.663      1.506 0.733   0 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                   mean     sd 0.025quant 0.5quant 0.975quant  mode #> Range for field 33.385 19.657      9.854   28.762      84.24 21.37 #> Stdev for field  0.594  0.218      0.277    0.557       1.12  0.49 #>  #> Deviance Information Criterion (DIC) ...............: 58.92 #> Deviance Information Criterion (DIC, saturated) ....: 13.28 #> Effective number of parameters .....................: 5.00 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 57.16 #> Effective number of parameters .................: 2.54 #>  #> Marginal log-Likelihood:  -36.55  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') x4pred <- data.frame(x = xs) pred2.bru <- predict(fit2.bru,   x4pred,   x ~ exp(field + Intercept),   n.samples = 1000 ) true.lambda <- data.frame(x = cd$x, y = E_nc2 / cd$exposure) ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_point(data = true.lambda, aes(x, y), pch = \"_\", cex = 9, col = \"blue\") +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\") ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_line(data = dat4pred2, aes(x, gam / exposure), lty = 2) +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\")"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_1d.html","id":"looking-at-the-posterior-distributions","dir":"Articles","previous_headings":"Fitting an SPDE model with inlabru","what":"Looking at the posterior distributions","title":"Random Fields in One Dimension","text":"can look Intercept posterior using function plot( ), .  know variable called Intercept order use function. see fixed effect parameters’ posterior distributions available plotted, can type tell SPDE parameters, type just tells SPDE fit2.bru called ‘field’, tell associated parameter names . parameters used estimation cryptic – interested range variance Matern covariance funcion, functions internal parameters. can look posterior distributions range parameter log variance parameters follows. (look posterior log variance variance posterior skewed easier view log variance)  can look posterior distributions Matern correlation covariance functions follows:","code":"plot(fit2.bru, \"Intercept\") names(fit2.bru$marginals.fixed) names(fit2.bru$marginals.random) #> [1] \"field\" spde.range <- spde.posterior(fit2.bru, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit2.bru, \"field\", what = \"log.variance\")  range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  (range.plot | var.plot) (plot(spde.posterior(fit2.bru, \"field\", what = \"matern.correlation\")) /  plot(spde.posterior(fit2.bru, \"field\", what = \"matern.covariance\")))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_2d.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"Random Fields in 2D","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(fmesher) library(mgcv) library(ggplot2) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_2d.html","id":"modelling-on-2d-domains","dir":"Articles","previous_headings":"","what":"Modelling on 2D domains","title":"Random Fields in 2D","text":"now construct 2D model, generate sample random field, attempt recover field observations locations. Tomorrow, look general mesh constructions adapt irregular domains. First, build high resolution mesh true field, using low level INLA functions  pointwise standard deviation field? Along straight boundaries, variance twice target variance. corners variance 4 times large.  Generate sample model:   Extract observations random locations:","code":"bnd <- spoly(   data.frame(     easting = c(0, 10, 10, 0),     northing = c(0, 0, 10, 10)   ),   format = \"sf\" ) ## For fmesher 0.3.0: ##   mesh_fine <- fm_mesh_2d_inla(boundary = bnd, max.edge = 0.2) ## For fmesher development version: mesh_fine <- fm_mesh_2d(   loc = fm_hexagon_lattice(bnd, edge_len = 0.2),   boundary = bnd,   max.edge = 0.3 ) ggplot() +   geom_fm(data = mesh_fine) # Note: the priors here will not be used in estimation matern_fine <-   inla.spde2.pcmatern(mesh_fine,     prior.sigma = c(1, 0.01),     prior.range = c(1, 0.01)   ) true_range <- 4 true_sigma <- 1 true_Q <- inla.spde.precision(matern_fine,   theta = log(c(true_range, true_sigma)) ) true_sd <- diag(inla.qinv(true_Q))^0.5 ggplot() +   gg(mesh_fine, color = true_sd) +   coord_equal() true_field <- inla.qsample(1, true_Q)[, 1]  truth <- expand.grid(   easting = seq(0, 10, length = 100),   northing = seq(0, 10, length = 100) ) truth <- sf::st_as_sf(truth, coords = c(\"easting\", \"northing\")) truth$field <- fm_evaluate(   mesh_fine,   loc = truth,   field = true_field )  pl_truth <- ggplot() +   gg(truth, aes(fill = field), geom = \"tile\") +   ggtitle(\"True field\") pl_truth ## Or with another colour scale: csc <- colsc(truth$field) multiplot(pl_truth, pl_truth + csc, cols = 2) n <- 200 mydata <- sf::st_as_sf(   data.frame(easting = runif(n, 0, 10), northing = runif(n, 0, 10)),   coords = c(\"easting\", \"northing\") ) mydata$observed <-   fm_evaluate(     mesh_fine,     loc = mydata,     field = true_field   ) +   rnorm(n, sd = 0.4) ggplot() +   gg(mydata, aes(col = observed))"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/articles/random_fields_2d.html","id":"estimating-the-field","dir":"Articles","previous_headings":"","what":"Estimating the field","title":"Random Fields in 2D","text":"Construct mesh covering data:  Construct SPDE model object Matern model: Specify model components: Fit model inspect results: Predict field lattice, generate single realisation posterior distribution: Compare truth estimated field (posterior mean sample posterior distribution):  Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object pred).","code":"## For fmesher 0.3.0: ##   mesh <- fm_mesh_2d_inla( ##     boundary = bnd, ##     max.edge = 0.5 ##  ) mesh <- fm_mesh_2d(   loc = fm_hexagon_lattice(bnd, edge_len = 0.5),   boundary = bnd,   max.edge = 0.6 ) ggplot() +   geom_fm(data = mesh) matern <-   inla.spde2.pcmatern(mesh,     prior.sigma = c(10, 0.01),     prior.range = c(1, 0.01)   ) cmp <- observed ~ field(geometry, model = matern) + Intercept(1) fit <- bru(cmp, mydata, family = \"gaussian\") summary(fit) pix <- fm_pixels(mesh, dims = c(200, 200)) pred <- predict(   fit,   pix,   ~ field + Intercept ) samp <- generate(   fit,   pix,   ~ field + Intercept,   n.samples = 1 ) pred$sample <- samp[, 1] pl_posterior_mean <- ggplot() +   gg(pred, geom = \"tile\") +   gg(bnd, alpha = 0) +   ggtitle(\"Posterior mean\") pl_posterior_sample <- ggplot() +   gg(pred, aes(fill = sample), geom = \"tile\") +   gg(bnd, alpha = 0) +   ggtitle(\"Posterior sample\")  # Common colour scale for the truth and estimate: csc <- colsc(truth$field, pred$mean, pred$sample) multiplot(pl_truth + csc,   pl_posterior_mean + csc,   pl_posterior_sample + csc,   cols = 3 ) int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit, \"field\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"field\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"field\", what = \"matern.covariance\")) multiplot(covplot, corplot) csc <- colsc(   pred[[\"median\"]],   pred[[\"q0.025\"]],   pred[[\"q0.975\"]] ) ## Common colour scale from SpatialPixelsDataFrame  gmedian <- ggplot() +   gg(pred[\"median\"], geom = \"tile\") +   csc glower95 <- ggplot() +   gg(pred[\"q0.025\"], geom = \"tile\") +   csc +   theme(legend.position = \"none\") gupper95 <- ggplot() +   gg(pred[\"q0.975\"], geom = \"tile\") +   csc +   theme(legend.position = \"none\")  multiplot(gmedian, glower95, gupper95,   layout = matrix(c(1, 1, 2, 3), byrow = TRUE, ncol = 2) )"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Finn Lindgren. Author, maintainer.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lindgren F (2025). inlabruCourseMay2025: Course Materials Edinburgh inlabru Course 19-20 May 2025. R package version 0.0.2, https://inlabru-org.github.io/inlabruCourseMay2025/.","code":"@Manual{,   title = {inlabruCourseMay2025: Course Materials for Edinburgh inlabru Course 19-20 May 2025},   author = {Finn Lindgren},   year = {2025},   note = {R package version 0.0.2},   url = {https://inlabru-org.github.io/inlabruCourseMay2025/}, }"},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"inlabrucoursemay2025","dir":"","previous_headings":"","what":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"course materials page package Edinburgh inlabru course, 19 20 May 2025. Follow menu links information tutorials, become available.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"event-overview","dir":"","previous_headings":"","what":"Event Overview","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"Bayesian Latent Gaussian Models (LGMs) closely related Generalized Additive Models (GAMs), offering Bayesian estimation uncertainty quantification spatial spatio-temporal models. INLA inlabru R packages combine Gaussian process models numerical optimization integration techniques, fast flexible analysis toolkit. taught part course provide overview LGM theory INLA/inlabru methods software, hands-sessions make sure attendees ready start spatial LGM modelling R soon course .","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"topics-covered","dir":"","previous_headings":"","what":"Topics covered","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"Basics latent Gaussian process models Bayesian spatial statistics context. principles INLA method fast Baysian inference, inlabru extensions non-linear models. inlabu package principles interface. Building spatial spatio-temporal models point-referenced, spatially aggregated, point pattern observations. Computing assessing posterior predictions visualisation. Diagnosing modelling problems.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"instructor","dir":"","previous_headings":"","what":"Instructor","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"Prof Finn Lindgren Chair Statistics School Mathematics, University Edinburgh. research focuses spatial spatio-temporal stochastic models, environmetrics, computational methods software. Among many others, co-authored influential paper “Explicit Link Gaussian Fields Gaussian Markov Random Fields: Stochastic Partial Differential Equation Approach,” published Journal Royal Statistical Society: Series B. Professor Lindgren contributed development several R packages, including INLA Bayesian latent Gaussian models inlabru, user-friendly interface INLA additional features","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"learning-outcomes","dir":"","previous_headings":"","what":"Learning outcomes","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"Understand basic theory underpinning spatial latent Gaussian process models Bayesian inference Use inlabru fit various spatial models data, including point-referenced, aggregated, point pattern data. able compute posterior predictions. Assess compare models","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"monday-195","dir":"","previous_headings":"Daily timetable (tentative)","what":"Monday 19/5","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"09:30 - 10:30 Lecture (Spatial modelling random fields) 10:30 - 11:00 coffee break 11:00 - 12:30 Lecture/Hands session (Introduction INLA/inlabru/fmesher) 12:30 - 13:30 Lunch 13:30 - 15:00 Lecture/Hands session (Spatial models point-referenced data) 15:00 - 15:30 break 15:30 - 17:00 Lecture/Hands session (Aggregated counts non-linear predictors) (Non-separable space-time)","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"tuesday-205","dir":"","previous_headings":"Daily timetable (tentative)","what":"Tuesday 20/5","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"09:30 - 10:30 Lecture (Point process models) 10:30 - 11:00 coffee break 11:00 - 12:30 Lecture/Hands session (Spatial covariates) (Space-time) 12:30 - 13:30 Lunch 13:30 - 15:00 Lecture/Hands session (Multi-likelihood models; hurdle models) 15:00 - 15:30 break 15:30 - 17:00 Lecture/Hands session (Predictive model assessment) (Spatially varying coefficients)","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"target-audience","dir":"","previous_headings":"","what":"Target audience","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"Anyone statistics training aware spatial data basics additive models benefit attending. Fields may popular : ecology, geosciences, ecology, epidemiology, public health, psychology, econometrics.","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/index.html","id":"assumed-knowledge","dir":"","previous_headings":"","what":"Assumed knowledge","title":"Course Materials for Edinburgh inlabru Course 19-20 May 2025","text":"Attendees comfortable using R. understand linear additive models, though can intuitive doesn’t mathematically rigorous. need used INLA inlabru .","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/reference/inlabruCourseMay2025-package.html","id":null,"dir":"Reference","previous_headings":"","what":"inlabruCourseMay2025: Course Materials for Edinburgh inlabru Course 19-20 May 2025 — inlabruCourseMay2025-package","title":"inlabruCourseMay2025: Course Materials for Edinburgh inlabru Course 19-20 May 2025 — inlabruCourseMay2025-package","text":"Course Materials Edinburgh inlabru Course 19-20 May 2025.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/reference/inlabruCourseMay2025-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"inlabruCourseMay2025: Course Materials for Edinburgh inlabru Course 19-20 May 2025 — inlabruCourseMay2025-package","text":"Maintainer: Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabruCourseMay2025/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. fmesher fm_as_bbox, fm_as_bbox_list, fm_as_dgCMatrix, fm_as_dgTMatrix, fm_as_fm, fm_as_fmesher_sparse, fm_as_lattice_2d, fm_as_lattice_2d_list, fm_as_lattice_Nd, fm_as_lattice_Nd_list, fm_as_list, fm_as_mesh_1d, fm_as_mesh_1d_list, fm_as_mesh_2d, fm_as_mesh_2d_list, fm_as_mesh_3d, fm_as_mesh_3d_list, fm_as_segm, fm_as_segm_list, fm_as_sfc, fm_as_sp_crs, fm_as_tensor, fm_as_tensor_list, fm_as_unpackedMatrix, fm_assess, fm_bary, fm_bary_loc, fm_bary_simplex, fm_basis, fm_basis_mesh_1d, fm_basis_mesh_2d, fm_bbox, fm_block, fm_block_eval, fm_block_log_shift, fm_block_log_weights, fm_block_logsumexp_eval, fm_block_prep, fm_block_weights, fm_call_stack, fm_caller_name, fm_centroids, fm_contains, fm_covariance, fm_cprod, fm_crs, fm_CRS, fm_CRS_as_list, fm_crs_bounds, fm_crs_detect_manifold, fm_crs_get_ellipsoid_radius, fm_crs_get_lengthunit, fm_crs_get_wkt, fm_crs_graticule, fm_crs_is_geocent, fm_crs_is_identical, fm_crs_is_null, fm_crs_oblique, fm_crs_oblique<-, fm_crs_plot, fm_crs_projection_type, fm_crs_set_ellipsoid_radius, fm_crs_set_lengthunit, fm_crs_tissot, fm_crs<-, fm_CRSargs, fm_CRSargs_as_list, fm_delaunay_2d, fm_delaunay_3d, fm_detect_manifold, fm_diameter, fm_dof, fm_ellipsoid_radius, fm_ellipsoid_radius<-, fm_evaluate, fm_evaluator, fm_evaluator_lattice, fm_extensions, fm_fem, fm_generate_colors, fm_has_PROJ6, fm_hexagon_lattice, fm_identical_CRS, fm_int, fm_int_mesh_2d, fm_int_mesh_2d_core, fm_int_multi_sampler, fm_is_bnd, fm_is_bnd<-, fm_is_within, fm_lattice_2d, fm_lattice_Nd, fm_length_unit, fm_length_unit<-, fm_list, fm_list_as_CRS, fm_manifold, fm_manifold_dim, fm_manifold_get, fm_manifold_type, fm_matern_precision, fm_matern_sample, fm_mesh_1d, fm_mesh_2d, fm_mesh_2d_inla, fm_mesh_2d_map, fm_mesh_2d_map_lim, fm_mesh_3d, fm_mesh_components, fm_mesh_intersection, fm_nonconvex_hull, fm_nonconvex_hull_inla, fm_nonconvex_hull_inla_basic, fm_pixels, fm_proj4string, fm_qinv, fm_raw_basis, fm_rcdt_2d, fm_rcdt_2d_inla, fm_refine, fm_row_kron, fm_safe_sp, fm_sample, fm_segm, fm_segm_contour_helper, fm_segm_join, fm_segm_split, fm_simplify, fm_simplify_helper, fm_sp_get_crs, fm_sp2segment, fm_split_lines, fm_spTransform, fm_store_points, fm_subdivide, fm_tensor, fm_transform, fm_try_callstack, fm_unify_coords, fm_vertex_projection, fm_vertices, fm_wkt, fm_wkt_as_wkt_tree, fm_wkt_get_ellipsoid_radius, fm_wkt_get_lengthunit, fm_wkt_is_geocent, fm_wkt_predef, fm_wkt_projection_type, fm_wkt_set_ellipsoid_radius, fm_wkt_set_lengthunit, fm_wkt_tree_as_wkt, fm_wkt_tree_get_item, fm_wkt_tree_projection_type, fm_wkt_tree_set_item, fm_wkt_unit_params, fmesher_bary, fmesher_bary3d, fmesher_fem, fmesher_globe_points, fmesher_mesh3d, fmesher_rcdt, fmesher_spherical_bsplines, fmesher_spherical_bsplines1, fmesher_split_lines, fmexample_sp, geom_fm, lines_rgl, local_fm_testthat_assign, local_fm_testthat_setup, local_fm_testthat_tolerances, plot_rgl inlabru add_mappers, .bru_options, bincount, bm_repeat_indexing, bm_repeat_indexing_matrix, bru, bru_call_options, bru_component, bru_component_list, bru_compute_linearisation, bru_convergence_plot, bru_eval_in_data_context, bru_fill_missing, bru_forward_transformation, bru_get_mapper, bru_get_mapper_safely, bru_index, bru_info, bru_inla.stack.mexpand, bru_inla.stack.mjoin, bru_inverse_transformation, bru_is_additive, bru_like_control_family, bru_like_inla_family, bru_like_list, bru_log, bru_log_abort, bru_log_bookmark, bru_log_bookmarks, bru_log_index, bru_log_message, bru_log_new, bru_log_offset, bru_log_reset, bru_log_warn, bru_make_stack, bru_mapper, bru_mapper_aggregate, bru_mapper_collect, bru_mapper_const, bru_mapper_define, bru_mapper_factor, bru_mapper_fmesher, bru_mapper_harmonics, bru_mapper_index, bru_mapper_linear, bru_mapper_logsumexp, bru_mapper_marginal, bru_mapper_matrix, bru_mapper_mesh_B, bru_mapper_multi, bru_mapper_pipe, bru_mapper_repeat, bru_mapper_scale, bru_mapper_shift, bru_mapper_sum, bru_mapper_taylor, bru_model, bru_obs, bru_options, bru_options_check, bru_options_default, bru_options_get, bru_options_reset, bru_options_set, bru_options_set_local, bru_rerun, bru_response_size, bru_safe_inla, bru_safe_sp, bru_standardise_names, bru_summarise, bru_timings, bru_timings_plot, bru_used, bru_used_update, bru_used_vars, comp_lin_eval, deltaIC, devel.cvmeasure, eval_spatial, evaluate_comp_simple, evaluate_effect_multi_state, evaluate_effect_single_state, evaluate_model, evaluate_state, fm_cprod, fm_crs, fm_int, fm_pixels, fm_sp2segment, generate, gg, globe, glplot, gmap, gorillas_sf_gcov, gorillas_sp, ibm_eval, ibm_eval2, ibm_inla_subset, ibm_invalid_output, ibm_is_linear, ibm_jacobian, ibm_linear, ibm_n, ibm_n_output, ibm_names, ibm_names<-, ibm_simplify, ibm_values, iinla, index_eval, inla_subset_eval, inla.spde2.pcmatern_B, input_eval, lgcp, like, like_list, local_basic_fixed_effect_testdata, local_basic_intercept_testdata, local_bru_options_set, local_bru_safe_inla, local_bru_testthat_assign, local_bru_testthat_setup, local_bru_testthat_tolerances, make_hierarchical_mesh_basis, mexdolphin_sp, multiplot, plotmarginal.inla, plotsample, point2count, row_kron, sample.lgcp, sline, spatial..ppp, spde.posterior, spoly","code":""}]
